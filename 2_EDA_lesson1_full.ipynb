{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi! This notebook is a labour of love. \n",
    "Please credit https://github.com/MargheritaPhilipp should you ever pass it on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Intro\n",
    "\n",
    "A bit on markdown and native python things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is written in mark down. Here you can \n",
    "1. Create numbered lists, make words **bold**, *italic*, or ***both***,\n",
    "- create bullet points lists\n",
    "and highlight `variable_names`\n",
    "\n",
    "Below are some example of things you can do that are just native to python and don't require the import of any libraries into your notebook.\n",
    "\n",
    "Also note that normally you would import all the libraries you need at the start of a .py or of your notebook. Here we make an exception to make it clear what sections use which of the libraries (at least for the first time within the notebook).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding numbers\n",
    "print(type(4.2))\n",
    "print(4.2 + 3.8 )\n",
    "\n",
    "# \"adding\" strings together\n",
    "print(type('hello'))\n",
    "print('hello' + \"_my_\" + 'friend')\n",
    "\n",
    "# \"adding\" lists together\n",
    "print(type(['do', 'I']))\n",
    "print(['do', 'I']+ ['know', \"you\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. EDA on WB pop data\n",
    "\n",
    "Each section links to some of the questions that were tasks in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Importing data\n",
    "\n",
    "Relative paths are better for collaboration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addresses the following questions from class:\n",
    "- Import the WB data (can you do it via a relative path?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# importing with absolute path: you won't be able to run this directly \n",
    "\n",
    "df = pd.read_csv('/Users/margheritaphilipp/Documents/GitHub/brushup/data/WB_pop_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# importing with relative path: if you have saved this file in a folder that has a data subfolder with the same csv inside, you can run this directly \n",
    "\n",
    "# get current working directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "df_og = pd.read_csv(cwd + '/data/WB_pop_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Starting inspection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addresses the following questions from class:\n",
    "- Display the head, check for missing values\n",
    "- Find the min and max values - overall and just for 2023\n",
    "- Which countries do they belong to?\n",
    "- Inspect the values in the “Country Code” column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the dimensions (rows and columns) of the data set and display first few rows\n",
    "print(df.shape)\n",
    "\n",
    "# other options:\n",
    "# df.tail(2)\n",
    "# df.sample(4)\n",
    "\n",
    "df_og.head() # default is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes not all columns are visible so it can be useful to get the full list\n",
    "\n",
    "df_og.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while .head() is a ***method*** I apply to the data frame, .shape and .columns are ***attributes*** of the data frame object/ class that I can call\n",
    "\n",
    "- Example with planets class (10 mins): https://www.youtube.com/watch?v=LwFnF9XoEf\n",
    "- Example with house class (7 mins): https://www.youtube.com/watch?v=3zoyA3U2Ka0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the info method also tells us which columns are present and what data type they contain\n",
    "# we know from the shape attribute that there are 218 rows and it seems that all rows contain data (are non-null), i.e. we don't have missing values\n",
    "\n",
    "df_og.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical summary of the numerical columns - we can already see a suspiciously high maximum value...\n",
    "\n",
    "df_og.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if I just want to find the min and max values for a speficic column:\n",
    "\n",
    "print('mix and max vals for 2023: ', df['2023'].min(), df['2023'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one way to get the whole row for these values is to use loc\n",
    "\n",
    "df_og.loc[df['2023'] == df['2023'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but this method is a bit more elegant and flexible\n",
    "\n",
    "df_og.nlargest(2, '2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og.nsmallest(5, ['2023', '2001'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting the country column: note that the lentgh of the value counts is 218, same as the number of unique values, so each country only appears once\n",
    "\n",
    "print(df_og['Country Name'].nunique()) # same as len(df['Country Name'].unique())\n",
    "\n",
    "print(df_og['Country Name'].unique())\n",
    "\n",
    "df_og['Country Name'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Basic manipulations and outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution and outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are there any outliers?\n",
    "    - Show them in a box plot.\n",
    "    - What could you do with them?\n",
    "- Can you plot a histogram and/ or kernel density for the values in 2023?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's good practice to make a copy of the data set before you start manipulating it\n",
    "# that way you also don't have to import the data from scratch each time you made an error (e.g. removing a column you end up wanting to keep)\n",
    "\n",
    "df = df_og.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install matplotlib # you may need to install matplotlib - which you can do directly in this notebook with the !pip3 :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "df.boxplot(column =['2003', '2013', '2023'], grid = False) # this is native to pandas which uses matplotlib without us having to call it\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we know the \"world\" row is the outlier, which is not a country, so let's remove it\n",
    "# remember: we can just re-run the cell that copies the og data to undo this change)\n",
    "\n",
    "# option 1: only keep other rows\n",
    "df = df[df['Country Name'] != 'World']\n",
    "\n",
    "# option 2: drop specific row\n",
    "#df = df.drop(df.loc[df['Country Name'] == 'World'])\n",
    "\n",
    "# option 3: see the option with ~ below (just search for the tilde with ctr+f)\n",
    "\n",
    "# check that there is one row less:\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns  # remember to install this in your environment first\n",
    "\n",
    "# plot again, this time with seaborn, and you can watch India overtake China\n",
    "\n",
    "sns.set_style(\"whitegrid\") \n",
    "\n",
    "columns_to_plot = ['2003', '2013', '2023']\n",
    "  \n",
    "sns.boxplot(data = df[columns_to_plot]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play with the bins variable of the histogram\n",
    "df.hist(column=['2023'], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "# kernel densities also give an idea of the overall distribution\n",
    "\n",
    "df['2023'].plot.density()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Population growth over time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which county has seen the greatest population growth from the start to the end of the timeline?\n",
    "    - In absolute terms?\n",
    "    - In relative terms?\n",
    "    - What about the greatest decrease?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column that shows the difference between 2001 and 2023 - not that the absolute value would not be helpful\n",
    "\n",
    "df['gwth_2023_2001_abs'] = df['2023'] - df['2001'] \n",
    "df['gwth_2023_2001_rel'] = round(df['gwth_2023_2001_abs'] / df['2001'], 2)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the highest growth values - you can of course to the equivalent for the smallest (i.e. most negative) values\n",
    "# bonus: can you find the countries with the samlles positive growth?\n",
    "\n",
    "print('Greatest absolute growth from 2001 to 2023: ')\n",
    "print('   - Country: ', df.nlargest(1, 'gwth_2023_2001_abs')['Country Name'])\n",
    "print('   - Growth: ', df.nlargest(1, 'gwth_2023_2001_abs')['gwth_2023_2001_abs'])\n",
    "\n",
    "print('\\n') # this prints a line break\n",
    "\n",
    "print('Greatest relative growth from 2001 to 2023: ')\n",
    "print('   - Country: ', df.nlargest(1, 'gwth_2023_2001_rel')['Country Name'])\n",
    "print('   - Growth: ', df.nlargest(1, 'gwth_2023_2001_rel')['gwth_2023_2001_rel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparing rows (countries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addresses the following questions from class:\n",
    "- Show just the rows for Spain and your country/ countries of origin\n",
    "    - Can you create a new row that shows the difference in population over time?\n",
    "    - Can you plot this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying only selected countries\n",
    "\n",
    "df.loc[( df['Country Name']== 'Germany') | (df['Country Name']== 'United Kingdom') | (df['Country Name']== 'Spain')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slightly neater and more flexible\n",
    "\n",
    "country_choices = ['Germany', 'United Kingdom', 'Spain']\n",
    "\n",
    "df.loc[df['Country Name'].isin(country_choices)].sort_values('2023', ascending=False) # here I am also specifying what to sort by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "# to take the difference row-wise, I need to select only the columns that contain numbers and are relevant\n",
    "\n",
    "year_cols = ['2001', '2002', '2003', '2011', '2012', '2013', '2021', '2022', '2023']\n",
    "\n",
    "df = df.copy() # otherwise you'll get a warning about assinging values that might overwrite existing ones\n",
    "\n",
    "# we can also make the index (i.e. the row name) more meaningful by inserting the country code\n",
    "df.set_index(df['Country Code'], inplace=True)\n",
    "\n",
    "# create rows if they don't exist\n",
    "if 'diff_deu_gbr' not in df.index:\n",
    "    df.loc['diff_deu_gbr'] = np.nan # making the default value Nan\n",
    "\n",
    "if 'diff_deu_esp' not in df_subset.index:\n",
    "    df.loc['diff_deu_esp'] = 0      # making the default value 0\n",
    "\n",
    "for col in year_cols:\n",
    "    df.loc['diff_deu_gbr', col] = df.loc['DEU', col] - df.loc['GBR', col]\n",
    "    df.loc['diff_deu_esp', col] = df.loc['DEU', col] - df.loc['ESP', col]\n",
    "\n",
    "df.loc[['DEU', 'GBR', 'ESP'], ['Country Name', 'Series Name'] + year_cols ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting from rows\n",
    "rows_to_plot = ['diff_deu_gbr', 'diff_deu_esp']\n",
    "data_to_plot = df.loc[rows_to_plot, numerical_cols]\n",
    "\n",
    "# transpose the data to make the columns the x-axis (years) and the rows the data series\n",
    "data_to_plot = data_to_plot.T\n",
    "\n",
    "# plot the data\n",
    "data_to_plot.plot(kind='line', marker='o', figsize=(10, 6))\n",
    "\n",
    "# specify labels and title\n",
    "plt.title('How much smaller UK and Spain are compared to Germany')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Values')\n",
    "plt.legend(title='Country/Row')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Better solution - using transpose to compare columns instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above is really cumbersome, so it's much easier to transpose the data from the beginning\n",
    "# to work only with the subset we can store it in a new data frame\n",
    "\n",
    "# country_choices = ['Germany', 'United Kingdom', 'Spain'] # this was already set above\n",
    "\n",
    "df_subset = df.loc[df['Country Name'].isin(country_choices) ]\n",
    "\n",
    "print(df_subset.shape)\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is what tranposing does - note the nice column names thanks to changing the index\n",
    "df_transposed = df_subset.T\n",
    "df_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can drop the repeated information to make it neaters\n",
    "\n",
    "to_drop = ['Country Code', 'Series Name', 'Series Code', 'Country Name'] # without this the transpose creates repeated values\n",
    "df_subset2 = df_subset.drop(columns=to_drop)\n",
    "\n",
    "df_transposed = pd.DataFrame(df_subset2.T)\n",
    "df_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now finding the differences is easier\n",
    "df_transposed['diff_deu_esp'] = df_transposed['DEU'] - df_transposed['ESP']\n",
    "df_transposed['diff_deu_gbr'] = df_transposed['DEU'] - df_transposed['GBR']\n",
    "df_transposed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Background cleaning\n",
    "\n",
    "What I did to give you a slightly nicer data set - shows how to store data frames as csvs and how to rename columns using a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WB = pd.read_csv(cwd + '/data/WB_full.csv')\n",
    "#df_meta = pd.read_csv(cwd + '/data/WB_metadata.csv')\n",
    "\n",
    "df_WB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_to_clean = [\n",
    "#     '2001 [YR2001]', '2002 [YR2002]', '2003 [YR2003]', '2011 [YR2011]',\n",
    "#     '2012 [YR2012]', '2013 [YR2013]', '2021 [YR2021]', '2022 [YR2022]', '2023 [YR2023]']\n",
    "\n",
    "# cols_to_clean might include other non-year columns\n",
    "cols_to_clean = df_WB.columns.tolist()\n",
    "\n",
    "# Creating a dictionary to map the year columns from '2001 [YR2001]' to just '2001'\n",
    "rename_dict = {col: col.split()[0] for col in cols_to_clean if '[YR' in col}\n",
    "\n",
    "# Using rename to only change the year columns and leave the rest intact\n",
    "df_WB = df_WB.rename(columns=rename_dict)\n",
    "\n",
    "df_WB.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop = df_WB.loc[df_WB['Series Code']=='SP.POP.TOTL']\n",
    "\n",
    "country_groups = [\n",
    "    \"AFE\", \"AFW\", \"ARB\", \"CSS\", \"CEB\", \"EAR\", \"EAS\", \"EAP\", \"TEA\", \"EMU\", \n",
    "    \"ECS\", \"ECA\", \"TEC\", \"EUU\", \"FCS\", \"HPC\", \"HIC\", \"IBD\", \"IBT\", \"IDB\", \n",
    "    \"IDX\", \"IDA\", \"LTE\", \"LCN\", \"LAC\", \"TLA\", \"LDC\", \"LMY\", \"LIC\", \"LMC\", \n",
    "    \"MEA\", \"MNA\", \"TMN\", \"MIC\", \"NAC\", \"INX\", \"OED\", \"OSS\", \"PSS\", \"PST\", \n",
    "    \"PRE\", \"SST\", \"SAS\", \"TSA\", \"SSF\", \"SSA\", \"TSS\", \"UMC\"]\n",
    "\n",
    "world = [\"WLD\"]\n",
    "\n",
    "filtered_df = df_pop[~df_pop['Country Code'].isin(country_groups)]\n",
    "\n",
    "filtered_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download\n",
    "#filtered_df.to_csv(cwd + '/data/WB_pop_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brushup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
