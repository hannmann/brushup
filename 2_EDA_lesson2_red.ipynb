{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. EDA on text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.read_csv(cwd + '/data/text_data.csv')\n",
    "print(df_text.shape)\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to wrap text of a specific cell\n",
    "def wrap_text(text, width=50):\n",
    "    \"\"\"Wrap text to the specified width.\"\"\"\n",
    "    return textwrap.fill(text, width)\n",
    "\n",
    "# Maximum width for line breaks\n",
    "max_width = 130\n",
    "\n",
    "# Iterate over each row and print the title and body with line breaks\n",
    "for index, row in df_text.iterrows():\n",
    "    wrapped_title = wrap_text(row['title'], max_width)\n",
    "    \n",
    "    print('country isocode:', row['country'])\n",
    "    print(f\"Title: {wrapped_title}\\n\")\n",
    "    print(\"-\" * 80) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text['keywords'] = df_text['title'].str.findall(r'\\b[A-Z][a-z]+\\b')\n",
    "\n",
    "df_text['contains_judge'] = df_text['title'].str.contains(r'\\b(Judge|Judges)\\b', regex=True)\n",
    "\n",
    "df_text['bigrams'] = df_text['title'].str.findall(r'\\b\\w+\\b \\b\\w+\\b')\n",
    "\n",
    "df_text['word_count_1'] = df_text['title'].str.count(r'\\b\\w+\\b')\n",
    "\n",
    "df_text['word_count_2'] = df_text['title'].str.split().str.len()\n",
    "\n",
    "df_text.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sentence = \"Hello, how are you? I'm ok thanks. How are you?\"\n",
    "\n",
    "list_of_words = my_sentence.split()\n",
    "print(list_of_words)\n",
    "re.findall(r'\\b[A-Z][a-z]+\\b', my_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Combining data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Differences:\n",
    "1. Merge combines two DataFrames based on one or more common columns.\n",
    "2. Concatenate appends DataFrames along a particular axis.\n",
    "3. Join combines DataFrames based on their index values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example DataFrames\n",
    "df1 = pd.DataFrame({\n",
    "    'employee_id': [101, 102, 103],\n",
    "    'name': ['Alice', 'Bob', 'Charlie']\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'employee_id': [101, 103, 104],\n",
    "    'department': ['HR', 'Engineering', 'Marketing']\n",
    "})\n",
    "\n",
    "df3 = pd.DataFrame({\n",
    "    'name': ['David', 'Eva'],\n",
    "    'department': ['Finance', 'HR']\n",
    "})\n",
    "\n",
    "df4 = pd.DataFrame({\n",
    "    'salary': [70000, 80000, 60000]\n",
    "})\n",
    "\n",
    "# two with the same index\n",
    "df5 = pd.DataFrame({\n",
    "    'age': [25, 30, 22],\n",
    "}, index=['Alice', 'Bob', 'Charlie'])\n",
    "\n",
    "df6 = pd.DataFrame({\n",
    "    'salary': [50000, 60000, 55000]\n",
    "}, index=['Alice', 'Bob', 'Charlie'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the difference the \"how\" parameter makes:\n",
    "\n",
    "Your options: how{‘left’, ‘right’, ‘outer’, ‘inner’, ‘cross’}, default ‘inner’\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on 'employee_id'\n",
    "merged_df = pd.merge(df1, df2, on='employee_id', how = 'inner')\n",
    "print(\"Merged DataFrame:\")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate two DataFrames along rows (axis=0)\n",
    "concatenated_df = pd.concat([df1, df3], ignore_index=True)\n",
    "print(\"\\nConcatenated DataFrame (Axis 0 - Rows):\")\n",
    "concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1)\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_columns_df = pd.concat([df1, df4], axis=1)\n",
    "print(\"\\nConcatenated DataFrame (Axis 1 - Columns):\")\n",
    "concatenated_columns_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df5)\n",
    "print(df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the two DataFrames\n",
    "joined_df = df5.join(df6)\n",
    "print(\"Joined DataFrame (Using Index):\")\n",
    "joined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. More on WB data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WB_more_data = pd.read_csv(cwd + '/data/WB_more_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the data\n",
    "df_og = df_WB_more_data.copy()\n",
    "\n",
    "# check what series and countries are included\n",
    "print(df_og['Series Name'].unique())\n",
    "print(df_og['Country Name'].nunique())\n",
    "df_og.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Melting and pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt the data frame \n",
    "year_cols = ['2001', '2002', '2003', '2011', '2012', '2013', '2021', '2022', '2023']\n",
    "\n",
    "df_melted = pd.melt(df_og, id_vars=['Country Name', 'Country Code', 'Series Name'], value_vars= year_cols, var_name='year', value_name='any_name')\n",
    "\n",
    "df_melted.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution\n",
    "print(df_melted.shape)\n",
    "print(df_melted['Series Name'].value_counts())\n",
    "print(df_melted['year'].value_counts())\n",
    "\n",
    "print(217*9)\n",
    "print(217*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot the data frame\n",
    "pivoted_df = df_melted.pivot(index=['Country Name', 'Country Code', 'year'], columns='Series Name', values='any_name').reset_index()\n",
    "print(pivoted_df.shape)\n",
    "pivoted_df.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Renaming & missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pivoted_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use renaming dictionary\n",
    "rename_dict = {\n",
    "    'Country Code' : 'isocode',\n",
    "    '??' : '???',\n",
    "    \n",
    "}\n",
    "\n",
    "df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "df.set_index('??', inplace= True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round to two decimal places\n",
    "\n",
    "df['primary_out_school_pct'] = round(df['primary_out_school_pct'],2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the missingness\n",
    "msno.matrix(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is going on?\n",
    "print(df.loc['AFG']['primary_out_school_total'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's fix it\n",
    "df.replace(???, np.nan, inplace=True)\n",
    "\n",
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep the rows that don't have missing values\n",
    "\n",
    "dropped = df.???()\n",
    "\n",
    "# what are we inspecting here?\n",
    "print(dropped.index.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets are useful for finding differences!\n",
    "diff_iso = set(df.country.unique()) - set(dropped.country.unique())\n",
    "len(diff_iso)\n",
    "print(diff_iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropped.to_csv(cwd + \"/data/WB_reshaped_nomissing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Groupby\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dropped.copy()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['???'] = df['???'].astype('???')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only now we can grouby\n",
    "\n",
    "df.groupby(['country'])['gni_pc'].agg(['???'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['gni_bil'] = round(df['gni']/1_000_000_000, 3)\n",
    "# df['pop_mil'] = round(df['gni']/1_000_000, 3)\n",
    "# df['gni_bil_pc'] = round(df['gni_pc']/1_000_000_000, 3)\n",
    "# df['prim_oos_pct'] = round(df['gni_pc']/1_000_000_000, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you estimate that working-age population is roughly 60% of the total population. You can create a dependency ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['primary_aged_total'] =\n",
    "df['primary_aged_of_pop'] = \n",
    "\n",
    "# using appy\n",
    "\n",
    "df['dependency'] = df.apply(\n",
    "    lambda row: row['primary_out_school_total'] / (row['pop'] * 0.6), axis=1\n",
    ")\n",
    "\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a lambda function and mapping a dictionary\n",
    "\n",
    "income_groups = {\n",
    "    lambda x: x < 1045: 'low',\n",
    "    lambda x: 1045 <= x < 4095: 'low_mid',\n",
    "    lambda x: 4095 <= x < 12695: 'upp_mid',\n",
    "    lambda x: x >= 12695: 'high'\n",
    "}\n",
    "\n",
    "df['income_group'] = df['gni_pc'].map(\n",
    "    lambda x: next((v for k, v in income_groups.items() if k(x)), None)\n",
    ")\n",
    "df.income_group.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highest_year = df.sort_values('???', ascending=False).drop_duplicates('???')\n",
    "df_highest_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highest_year.boxplot(column='???')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highest_year.gni_pc.nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the box plot only for a given income group\n",
    "df_highest_year.loc[???].boxplot(column='gni_pc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = ['high', 'upp_mid', 'low_mid', 'low']\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(1, len(groups), figsize=(12, 6))\n",
    "\n",
    "# Loop through each group and create a boxplot in the corresponding subplot\n",
    "for i, group in enumerate(groups):\n",
    "    df_highest_year.loc[df_highest_year['income_group'] == ???].boxplot(column='gni_pc', ax=axes[???])\n",
    "    axes[i].set_title(group)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare\n",
    "df_highest_year.plot.scatter(x='???', y='???')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare\n",
    "df_highest_year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(1, len(groups), figsize=(12, 6))\n",
    "\n",
    "# Loop through each group and create a boxplot in the corresponding subplot\n",
    "for i, group in enumerate(groups):\n",
    "    ???\n",
    "    axes[i].set_title(group)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Background cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WB = pd.read_csv(cwd + '/data/WB_full.csv')\n",
    "#df_meta = pd.read_csv(cwd + '/data/WB_metadata.csv')\n",
    "\n",
    "df_WB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean column names\n",
    "cols_to_clean = df_WB.columns.tolist()\n",
    "rename_dict = {col: col.split()[0] for col in cols_to_clean if '[YR' in col}\n",
    "df_WB = df_WB.rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The net enrollment rate excludes overage and underage students and more accurately captures the system's coverage and internal efficiency. Differences between the gross enrollment ratio and the net enrollment rate show the incidence of overage and underage enrollments.\n",
    "https://databank.worldbank.org/metadataglossary/world-development-indicators/series/SE.PRE.ENRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WB['Series Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_to_keep = ['Population, total',\n",
    "                  'GNI, Atlas method (current US$)', 'GNI per capita, Atlas method (current US$)',\n",
    "                  'Children out of school, primary',\n",
    "                  'Children out of school (% of primary school age)'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_choice = df_WB.loc[df_WB['Series Name'].isin(series_to_keep)]\n",
    "\n",
    "country_groups = [\n",
    "    \"AFE\", \"AFW\", \"ARB\", \"CSS\", \"CEB\", \"EAR\", \"EAS\", \"EAP\", \"TEA\", \"EMU\", \n",
    "    \"ECS\", \"ECA\", \"TEC\", \"EUU\", \"FCS\", \"HPC\", \"HIC\", \"IBD\", \"IBT\", \"IDB\", \n",
    "    \"IDX\", \"IDA\", \"LTE\", \"LCN\", \"LAC\", \"TLA\", \"LDC\", \"LMY\", \"LIC\", \"LMC\", \n",
    "    \"MEA\", \"MNA\", \"TMN\", \"MIC\", \"NAC\", \"INX\", \"OED\", \"OSS\", \"PSS\", \"PST\", \n",
    "    \"PRE\", \"SST\", \"SAS\", \"TSA\", \"SSF\", \"SSA\", \"TSS\", \"UMC\"]\n",
    "\n",
    "world = [\"WLD\"]\n",
    "\n",
    "filtered_df = df_choice[~df_choice['Country Code'].isin(country_groups + world)]\n",
    "\n",
    "# download data\n",
    "#filtered_df.to_csv(cwd + '/data/WB_more_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.sample(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brushup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
